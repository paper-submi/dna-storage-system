## Disclaimer
This repository is a COPY of the official original repository, created by the original author itself.
It is created to anonimize the submission of the paper for a conference.


# RMS: Reliable Molecular Storage system
This branch contains all you need to create a container and run our DNA storage pipeline.
By default, it will use 30% redundancy to encode data.

## Installation

Create the docker image and run it on a container.

You can build the docker image using the script:
```
./oa-build-docker.sh
```
**Note:** It may require some time

You can create a container with the oligoarchive image you just created running:
```
./oa-run-docker.sh
```

Once you logged in the container, run the script:

```
./setup.sh
```
It will compile all the source code and generate a `config` file in the `data` directory. 

##### IMPORTANT: Remember to add the path to the encoding tables in the config file. 
The path can be where the encoding tables already exists or where you want they will be created.

Be sure that the encoding matrices are in the directory `oa-dsm/src/LDPC-codes/matrices`.
By default, the decoder will encode with 30% redundancy.
 
### Data needed

1. Encoding tables. If not provided, they will be created at first run on the decoder
2. Encoding matrixes. You need the corresponding matrix based on the redundancy you want to create.

**Note:** <br>
When the container is created the 30% and 10% redundancy matrixes will be downloaded and installed in the directory: `oa-dsm/src/LDPC-codes/matrices**`

* As alternative to the download - the matrix for LDPC **X%** redunduncy can be created during the setup uncommenting line 9-17. It requires sometimes. *(not suggested)*

## Data directory structure

The **data** directory contains:
* the *file* to encode;
* the encoding oligos in FASTA format;
* the sequenced reads in FASTQ format ;
* the configuration file (*config*) used by the encoder/decoder;
* the parameters file (*params*) used during the encoding and to be used in the decoding;
* files containing left and right primers

The **data/extents** directory contains:
* a directory for each extent **ext_[0..N]**

The **ext_[0..N]** directory contains:
* the reads corresponding to the i-th extent;
* a **tmp_data** to save the temporary files generated by the decoder;
* the clusters centroids with the cardinality of the corresponding cluster and the probability for each centroid's motif ( respectively in the files *clusters*, *clusters.pts* and *clusters.prob* )

#### Note
Be sure that **data/extents/ext_\*/** exist before running any program.


### Encoding
```
bash encode.sh  -f path-to-file -g data/config -p data/params
```

### Sequencing simulator
**Parameters:**<br>
* **-h**: display this help and exit.<br>
* **-s BADREAD/BBMAP**:    simulator to use **[ badread/bbmap ]**.<br>
* **-i INPUT_FILE**:       FASTA file containing the encoding oligos.<br>
* **-o OUTPUT_FILE**:      FASTQ file containing the simulated reads.<br>
* **-m MIN_LENGTH**:       min length of the simulated reads **[needed only with BBMAP]**.<br>
* **-M MAX_LENGTH:**       max length of the simulated reads **[needed only with BBMAP]**.<br>
* **-c COV**:              coverage to use in the simulation.<br>

**BADREAD:**
Not supported anymore

**BBMAP:**
```
bash run_simulator.sh -s bbmap -c COV - i path/to/FASTA -o path/to/FASTQ -m min_l -M max_l
```

### Decoding
**Parameters:**
* **-h**                  display this help and exit.<br>
* **-r READS_FILEPATH**   dataset containing reads to process.<br>
* **-5 L_PRIMER_FILE**    left primer file.<br>
* **-3 R_PRIMER_FILE**    right primer file.<br>
* **-l N**                length of the reference oligos.<br>
* **-p N**                min number of points to consider valid a centroid
* **-d DATA_DIR_PATH**    path to data directory
* **-e ED**             edit distance for primer alignment
```
bash decode.sh -g data/config -p data/params
```
